{
  "api/Microsoft.Extensions.DependencyInjection.RegistrationExtension.html": {
    "href": "api/Microsoft.Extensions.DependencyInjection.RegistrationExtension.html",
    "title": "Class RegistrationExtension | Spidey API Reference",
    "keywords": "Class RegistrationExtension Namespace Microsoft.Extensions.DependencyInjection Assembly Spidey.dll Registration extension methods public static class RegistrationExtension Inheritance object RegistrationExtension Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Methods RegisterSpidey(ICanisterConfiguration?) Registers the library with the bootstrapper. public static ICanisterConfiguration? RegisterSpidey(this ICanisterConfiguration? bootstrapper) Parameters bootstrapper ICanisterConfiguration The bootstrapper. Returns ICanisterConfiguration The bootstrapper"
  },
  "api/Microsoft.Extensions.DependencyInjection.html": {
    "href": "api/Microsoft.Extensions.DependencyInjection.html",
    "title": "Namespace Microsoft.Extensions.DependencyInjection | Spidey API Reference",
    "keywords": "Namespace Microsoft.Extensions.DependencyInjection Classes RegistrationExtension Registration extension methods"
  },
  "api/Spidey.Crawler.html": {
    "href": "api/Spidey.Crawler.html",
    "title": "Class Crawler | Spidey API Reference",
    "keywords": "Class Crawler Namespace Spidey Assembly Spidey.dll Crawler class public class Crawler : IDisposable Inheritance object Crawler Implements IDisposable Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors Crawler(Options?) Initializes a new instance of the Crawler class. public Crawler(Options? options = null) Parameters options Options The options. Crawler(IEnumerable<IPipeline>, Options?) Initializes a new instance of the Crawler class. public Crawler(IEnumerable<IPipeline> pipelines, Options? options = null) Parameters pipelines IEnumerable<IPipeline> The pipelines. options Options The options. Methods Dispose() Disposes of the internal objects public void Dispose() Dispose(bool) Disposes the internal objects protected virtual void Dispose(bool Value) Parameters Value bool StartCrawlAsync() Starts crawling. public Task<Results?> StartCrawlAsync() Returns Task<Results> The listing of each URL and where it was found. See Also IDisposable"
  },
  "api/Spidey.Engines.DefaultContentParser.html": {
    "href": "api/Spidey.Engines.DefaultContentParser.html",
    "title": "Class DefaultContentParser | Spidey API Reference",
    "keywords": "Class DefaultContentParser Namespace Spidey.Engines Assembly Spidey.dll Default content parser public class DefaultContentParser : IContentParser Inheritance object DefaultContentParser Implements IContentParser Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors DefaultContentParser(Options?, IEnumerable<ILinkDiscoverer>, RecyclableMemoryStreamManager, ILogger<DefaultContentParser>?) Initializes a new instance of the DefaultContentParser class. public DefaultContentParser(Options? options, IEnumerable<ILinkDiscoverer> linkDiscoverers, RecyclableMemoryStreamManager recyclableMemoryStreamManager, ILogger<DefaultContentParser>? logger = null) Parameters options Options The options. linkDiscoverers IEnumerable<ILinkDiscoverer> The link discoverers. recyclableMemoryStreamManager RecyclableMemoryStreamManager The recyclable memory stream manager. logger ILogger<DefaultContentParser> The logger. Methods Parse(UrlData?) Parses the specified options. public ResultFile? Parse(UrlData? data) Parameters data UrlData The data. Returns ResultFile Result file See Also IContentParser"
  },
  "api/Spidey.Engines.DefaultEngine.html": {
    "href": "api/Spidey.Engines.DefaultEngine.html",
    "title": "Class DefaultEngine | Spidey API Reference",
    "keywords": "Class DefaultEngine Namespace Spidey.Engines Assembly Spidey.dll Default engine public class DefaultEngine : IEngine, IDisposable Inheritance object DefaultEngine Implements IEngine IDisposable Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors DefaultEngine(Options?, ILogger<DefaultEngine>?) Initializes a new instance of the DefaultEngine class. public DefaultEngine(Options? options, ILogger<DefaultEngine>? logger = null) Parameters options Options The options. logger ILogger<DefaultEngine> The logger. Methods CrawlAsync(string) Crawls the url. public Task<UrlData?> CrawlAsync(string url) Parameters url string The URL. Returns Task<UrlData> The data from the URL. Dispose() Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources. public void Dispose() See Also IEngine"
  },
  "api/Spidey.Engines.DefaultLinkDiscoverer.html": {
    "href": "api/Spidey.Engines.DefaultLinkDiscoverer.html",
    "title": "Class DefaultLinkDiscoverer | Spidey API Reference",
    "keywords": "Class DefaultLinkDiscoverer Namespace Spidey.Engines Assembly Spidey.dll Default link engine public class DefaultLinkDiscoverer : ILinkDiscoverer Inheritance object DefaultLinkDiscoverer Implements ILinkDiscoverer Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors DefaultLinkDiscoverer(Options?) Initializes a new instance of the DefaultLinkDiscoverer class. public DefaultLinkDiscoverer(Options? options) Parameters options Options The options. Methods DiscoverUrls(string, string, byte[], string) Discovers the urls. public string[] DiscoverUrls(string currentDomain, string url, byte[] content, string contentType) Parameters currentDomain string The current domain. url string The URL. content byte[] The content. contentType string Type of the content. Returns string[] The links within the document. FixUrl(string, string?, Dictionary<Regex, string>) Fixes the URL. public string FixUrl(string currentDomain, string? link, Dictionary<Regex, string> replacements) Parameters currentDomain string The current domain. link string The link. replacements Dictionary<Regex, string> The replacements. Returns string The fixed URL GetDomain(string) Gets the domain. public string GetDomain(string url) Parameters url string The URL. Returns string The domain of the url. See Also ILinkDiscoverer"
  },
  "api/Spidey.Engines.DefaultPipeline.html": {
    "href": "api/Spidey.Engines.DefaultPipeline.html",
    "title": "Class DefaultPipeline | Spidey API Reference",
    "keywords": "Class DefaultPipeline Namespace Spidey.Engines Assembly Spidey.dll Default pipeline public class DefaultPipeline : IPipeline, IDisposable Inheritance object DefaultPipeline Implements IPipeline IDisposable Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors DefaultPipeline(IEnumerable<IScheduler>, IEnumerable<IProcessor>, IEnumerable<IContentParser>, IEnumerable<ILinkDiscoverer>, Options?, ILogger<DefaultPipeline>?) Initializes a new instance of the DefaultPipeline class. public DefaultPipeline(IEnumerable<IScheduler> schedulers, IEnumerable<IProcessor> processors, IEnumerable<IContentParser> parsers, IEnumerable<ILinkDiscoverer> linkDiscoverers, Options? options, ILogger<DefaultPipeline>? logger = null) Parameters schedulers IEnumerable<IScheduler> The schedulers. processors IEnumerable<IProcessor> The processors. parsers IEnumerable<IContentParser> The parsers. linkDiscoverers IEnumerable<ILinkDiscoverer> The link discoverers. options Options The options. logger ILogger<DefaultPipeline> The logger. Methods Dispose() Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources. public void Dispose() StartCrawlAsync() Starts the crawl asynchronous. public Task<Results?> StartCrawlAsync() Returns Task<Results> The results from the crawl. See Also IPipeline"
  },
  "api/Spidey.Engines.DefaultProcessor.html": {
    "href": "api/Spidey.Engines.DefaultProcessor.html",
    "title": "Class DefaultProcessor | Spidey API Reference",
    "keywords": "Class DefaultProcessor Namespace Spidey.Engines Assembly Spidey.dll Default processor public class DefaultProcessor : IProcessor Inheritance object DefaultProcessor Implements IProcessor Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors DefaultProcessor(Options?, ILogger<DefaultProcessor>?) Initializes a new instance of the DefaultProcessor class. public DefaultProcessor(Options? options, ILogger<DefaultProcessor>? logger = null) Parameters options Options The options. logger ILogger<DefaultProcessor> The logger. Methods Process(ResultFile) Processes the item found. public void Process(ResultFile resultFile) Parameters resultFile ResultFile The result file. See Also IProcessor"
  },
  "api/Spidey.Engines.DefaultScheduler.html": {
    "href": "api/Spidey.Engines.DefaultScheduler.html",
    "title": "Class DefaultScheduler | Spidey API Reference",
    "keywords": "Class DefaultScheduler Namespace Spidey.Engines Assembly Spidey.dll Default scheduler public class DefaultScheduler : IScheduler, IDisposable Inheritance object DefaultScheduler Implements IScheduler IDisposable Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors DefaultScheduler(Options?, IEnumerable<IEngine>, ILogger<DefaultScheduler>?) Initializes a new instance of the DefaultScheduler class. public DefaultScheduler(Options? options, IEnumerable<IEngine> engines, ILogger<DefaultScheduler>? logger = null) Parameters options Options The options. engines IEnumerable<IEngine> The engines. logger ILogger<DefaultScheduler> The logger. Methods CrawlAsync(string) Schedules the specified URL for crawling. public Task<UrlData?> CrawlAsync(string url) Parameters url string The URL. Returns Task<UrlData> This. Dispose() Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources. public void Dispose() See Also IScheduler"
  },
  "api/Spidey.Engines.Interfaces.IContentParser.html": {
    "href": "api/Spidey.Engines.Interfaces.IContentParser.html",
    "title": "Interface IContentParser | Spidey API Reference",
    "keywords": "Interface IContentParser Namespace Spidey.Engines.Interfaces Assembly Spidey.dll Content parser interface public interface IContentParser Methods Parse(UrlData?) Parses the specified options. ResultFile? Parse(UrlData? data) Parameters data UrlData The data. Returns ResultFile Result file"
  },
  "api/Spidey.Engines.Interfaces.IEngine.html": {
    "href": "api/Spidey.Engines.Interfaces.IEngine.html",
    "title": "Interface IEngine | Spidey API Reference",
    "keywords": "Interface IEngine Namespace Spidey.Engines.Interfaces Assembly Spidey.dll Engine interface public interface IEngine : IDisposable Inherited Members IDisposable.Dispose() Methods CrawlAsync(string) Crawls the specified URL. Task<UrlData?> CrawlAsync(string url) Parameters url string The URL. Returns Task<UrlData> The data from the url. See Also IDisposable"
  },
  "api/Spidey.Engines.Interfaces.ILinkDiscoverer.html": {
    "href": "api/Spidey.Engines.Interfaces.ILinkDiscoverer.html",
    "title": "Interface ILinkDiscoverer | Spidey API Reference",
    "keywords": "Interface ILinkDiscoverer Namespace Spidey.Engines.Interfaces Assembly Spidey.dll Link engine interface public interface ILinkDiscoverer Methods DiscoverUrls(string, string, byte[], string) Discovers the urls. string[] DiscoverUrls(string currentDomain, string url, byte[] content, string contentType) Parameters currentDomain string The current domain. url string The URL. content byte[] The content. contentType string Type of the content. Returns string[] The links within the document. FixUrl(string, string, Dictionary<Regex, string>) Fixes the URL. string FixUrl(string currentDomain, string link, Dictionary<Regex, string> replacements) Parameters currentDomain string The current domain. link string The link. replacements Dictionary<Regex, string> The replacements. Returns string Fixed URL GetDomain(string) Gets the domain. string GetDomain(string url) Parameters url string The URL. Returns string The domain of the url."
  },
  "api/Spidey.Engines.Interfaces.IPipeline.html": {
    "href": "api/Spidey.Engines.Interfaces.IPipeline.html",
    "title": "Interface IPipeline | Spidey API Reference",
    "keywords": "Interface IPipeline Namespace Spidey.Engines.Interfaces Assembly Spidey.dll Pipeline interface public interface IPipeline : IDisposable Inherited Members IDisposable.Dispose() Methods StartCrawlAsync() Starts the crawl asynchronous. Task<Results?> StartCrawlAsync() Returns Task<Results> The results from the crawl. See Also IDisposable"
  },
  "api/Spidey.Engines.Interfaces.IProcessor.html": {
    "href": "api/Spidey.Engines.Interfaces.IProcessor.html",
    "title": "Interface IProcessor | Spidey API Reference",
    "keywords": "Interface IProcessor Namespace Spidey.Engines.Interfaces Assembly Spidey.dll Processor interface public interface IProcessor Methods Process(ResultFile) Processes the item found. void Process(ResultFile resultFile) Parameters resultFile ResultFile The result file."
  },
  "api/Spidey.Engines.Interfaces.IScheduler.html": {
    "href": "api/Spidey.Engines.Interfaces.IScheduler.html",
    "title": "Interface IScheduler | Spidey API Reference",
    "keywords": "Interface IScheduler Namespace Spidey.Engines.Interfaces Assembly Spidey.dll Schedules the individual URLs to the workers. public interface IScheduler : IDisposable Inherited Members IDisposable.Dispose() Methods CrawlAsync(string) Schedules the specified URL for crawling. Task<UrlData?> CrawlAsync(string url) Parameters url string The URL. Returns Task<UrlData> Schedules the individual URLs to the workers. See Also IDisposable"
  },
  "api/Spidey.Engines.Interfaces.html": {
    "href": "api/Spidey.Engines.Interfaces.html",
    "title": "Namespace Spidey.Engines.Interfaces | Spidey API Reference",
    "keywords": "Namespace Spidey.Engines.Interfaces Interfaces IContentParser Content parser interface IEngine Engine interface ILinkDiscoverer Link engine interface IPipeline Pipeline interface IProcessor Processor interface IScheduler Schedules the individual URLs to the workers."
  },
  "api/Spidey.Engines.Scheduler.Worker.html": {
    "href": "api/Spidey.Engines.Scheduler.Worker.html",
    "title": "Class Worker | Spidey API Reference",
    "keywords": "Class Worker Namespace Spidey.Engines.Scheduler Assembly Spidey.dll Worker class public class Worker : IDisposable Inheritance object Worker Implements IDisposable Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors Worker(IEngine) Initializes a new instance of the Worker class. public Worker(IEngine engine) Parameters engine IEngine The engine. Properties CurrentTask Gets or sets the current task. public Task CurrentTask { get; } Property Value Task The current task. Done Gets a value indicating whether this Worker is done. public bool Done { get; } Property Value bool true if done; otherwise, false. Methods CrawlAsync(string) Crawls the url asynchronously. public Task<UrlData?> CrawlAsync(string url) Parameters url string The URL. Returns Task<UrlData> The url data. Dispose() Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources. public void Dispose() See Also IDisposable"
  },
  "api/Spidey.Engines.Scheduler.WorkerPool.html": {
    "href": "api/Spidey.Engines.Scheduler.WorkerPool.html",
    "title": "Class WorkerPool | Spidey API Reference",
    "keywords": "Class WorkerPool Namespace Spidey.Engines.Scheduler Assembly Spidey.dll Worker pool public class WorkerPool : IDisposable Inheritance object WorkerPool Implements IDisposable Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors WorkerPool(int, IEngine, CancellationToken) Initializes a new instance of the WorkerPool class. public WorkerPool(int workerCount, IEngine engine, CancellationToken cancellationToken) Parameters workerCount int The worker count. engine IEngine The engine. cancellationToken CancellationToken The cancellation token. Properties Done Gets a value indicating whether this WorkerPool is done. public bool Done { get; } Property Value bool true if done; otherwise, false. IsCanceled Gets a value indicating whether this instance is canceled. public bool IsCanceled { get; } Property Value bool true if this instance is canceled; otherwise, false. Methods CrawlAsync(string) Processes the request. public Task<UrlData?> CrawlAsync(string url) Parameters url string The URL. Returns Task<UrlData> Task. Dispose() Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources. public void Dispose() See Also IDisposable"
  },
  "api/Spidey.Engines.Scheduler.html": {
    "href": "api/Spidey.Engines.Scheduler.html",
    "title": "Namespace Spidey.Engines.Scheduler | Spidey API Reference",
    "keywords": "Namespace Spidey.Engines.Scheduler Classes Worker Worker class WorkerPool Worker pool"
  },
  "api/Spidey.Engines.UrlData.html": {
    "href": "api/Spidey.Engines.UrlData.html",
    "title": "Class UrlData | Spidey API Reference",
    "keywords": "Class UrlData Namespace Spidey.Engines Assembly Spidey.dll URL data passed back from the engine. public class UrlData Inheritance object UrlData Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors UrlData(byte[], string, string, string, int, string) Initializes a new instance of the UrlData class. public UrlData(byte[] content, string contentType, string fileName, string finalLocation, int statusCode, string uRL) Parameters content byte[] The content. contentType string Type of the content. fileName string Name of the file. finalLocation string The final location. statusCode int The status code. uRL string The u rl. Properties Content Gets or sets the content. public byte[] Content { get; set; } Property Value byte[] The content. ContentType Gets or sets the type of the content. public string ContentType { get; set; } Property Value string The type of the content. FileName Gets or sets the name of the file. public string FileName { get; set; } Property Value string The name of the file. FinalLocation Gets or sets the final location. public string FinalLocation { get; set; } Property Value string The final location. StatusCode Gets or sets the status code. public int StatusCode { get; set; } Property Value int The status code. URL Gets or sets the URL. public string URL { get; set; } Property Value string The URL."
  },
  "api/Spidey.Engines.html": {
    "href": "api/Spidey.Engines.html",
    "title": "Namespace Spidey.Engines | Spidey API Reference",
    "keywords": "Namespace Spidey.Engines Classes DefaultContentParser Default content parser DefaultEngine Default engine DefaultLinkDiscoverer Default link engine DefaultPipeline Default pipeline DefaultProcessor Default processor DefaultScheduler Default scheduler UrlData URL data passed back from the engine."
  },
  "api/Spidey.ErrorItem.html": {
    "href": "api/Spidey.ErrorItem.html",
    "title": "Class ErrorItem | Spidey API Reference",
    "keywords": "Class ErrorItem Namespace Spidey Assembly Spidey.dll Error item data holder. public class ErrorItem Inheritance object ErrorItem Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors ErrorItem(Exception, string, int) Initializes a new instance of the ErrorItem class. public ErrorItem(Exception error, string url, int statusCode) Parameters error Exception The error. url string The URL. statusCode int The status code. Properties Error Gets or sets the error. public Exception Error { get; set; } Property Value Exception The error. StatusCode Gets or sets the status code. public int StatusCode { get; set; } Property Value int The status code. Url Gets or sets the URL. public string Url { get; set; } Property Value string The URL."
  },
  "api/Spidey.Modules.SpideyModule.html": {
    "href": "api/Spidey.Modules.SpideyModule.html",
    "title": "Class SpideyModule | Spidey API Reference",
    "keywords": "Class SpideyModule Namespace Spidey.Modules Assembly Spidey.dll Spidey module public class SpideyModule : IModule Inheritance object SpideyModule Implements IModule Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties Order Order to run it in public int Order { get; } Property Value int Spidey module Methods Load(IServiceCollection?) Loads the module public void Load(IServiceCollection? bootstrapper) Parameters bootstrapper IServiceCollection The bootstrapper. See Also IModule"
  },
  "api/Spidey.Modules.html": {
    "href": "api/Spidey.Modules.html",
    "title": "Namespace Spidey.Modules | Spidey API Reference",
    "keywords": "Namespace Spidey.Modules Classes SpideyModule Spidey module"
  },
  "api/Spidey.Options.html": {
    "href": "api/Spidey.Options.html",
    "title": "Class Options | Spidey API Reference",
    "keywords": "Class Options Namespace Spidey Assembly Spidey.dll Basic options class public class Options Inheritance object Options Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties Allow Gets or sets the allowed items. public List<string> Allow { get; set; } Property Value List<string> The allowed items. Credentials Gets the credentials. public NetworkCredential? Credentials { get; set; } Property Value NetworkCredential The credentials. Default Gets the default. public static Options Default { get; } Property Value Options The default. FollowOnly Gets or sets the follow only list. public List<string> FollowOnly { get; set; } Property Value List<string> The follow only list. Ignore Gets or sets the ignore list. public List<string> Ignore { get; set; } Property Value List<string> The ignore list. ItemFound Gets or sets the item found. public Action<ResultFile> ItemFound { get; set; } Property Value Action<ResultFile> The item found. MaxDelay Gets or sets the maximum delay. public int MaxDelay { get; set; } Property Value int The maximum delay. MinDelay Gets or sets the minimum delay. public int MinDelay { get; set; } Property Value int The minimum delay. NumberWorkers Gets or sets the number workers. public int NumberWorkers { get; set; } Property Value int The number workers. Proxy Gets the proxy. public IWebProxy? Proxy { get; set; } Property Value IWebProxy The proxy. StartLocations Gets or sets the start locations. public List<string> StartLocations { get; set; } Property Value List<string> The start locations. UrlReplacements Gets or sets a list of replacements for URL parts. Key is the url part that you may find, value is the replacement for it. public Dictionary<string, string> UrlReplacements { get; set; } Property Value Dictionary<string, string> The domain replacements. UseDefaultCredentials Gets or sets a value indicating whether [use default credentials]. public bool UseDefaultCredentials { get; set; } Property Value bool true if [use default credentials]; otherwise, false."
  },
  "api/Spidey.ResultFile.html": {
    "href": "api/Spidey.ResultFile.html",
    "title": "Class ResultFile | Spidey API Reference",
    "keywords": "Class ResultFile Namespace Spidey Assembly Spidey.dll Result file public class ResultFile Inheritance object ResultFile Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors ResultFile(string, UrlData, IGenericFile, string, string, string, int) Initializes a new instance of the ResultFile class. public ResultFile(string contentType, UrlData data, IGenericFile fileContent, string fileName, string finalLocation, string location, int statusCode) Parameters contentType string Type of the content. data UrlData The data. fileContent IGenericFile Content of the file. fileName string Name of the file. finalLocation string The final location. location string The location. statusCode int The status code. Properties ContentType Gets or sets the type of the content. public string ContentType { get; set; } Property Value string The type of the content. Data Gets or sets the data. public UrlData Data { get; set; } Property Value UrlData The data. FileContent Gets or sets the file. public IGenericFile FileContent { get; set; } Property Value IGenericFile The file. FileName Gets or sets the name of the file if this is something downloaded. public string FileName { get; set; } Property Value string The name of the file if this is something downloaded. FinalLocation Gets or sets the final location (if page is redirected, this will be different than location). public string FinalLocation { get; set; } Property Value string The final location. Location Gets the file location. public string Location { get; set; } Property Value string The file location. StatusCode Gets or sets the status code. public int StatusCode { get; set; } Property Value int The status code."
  },
  "api/Spidey.Results.html": {
    "href": "api/Spidey.Results.html",
    "title": "Class Results | Spidey API Reference",
    "keywords": "Class Results Namespace Spidey Assembly Spidey.dll Results from the crawl public class Results Inheritance object Results Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties CompletedURLs Gets or sets the completed urls. public ConcurrentBag<string> CompletedURLs { get; } Property Value ConcurrentBag<string> The completed urls. ErrorURLs Gets or sets the error ur ls. public ConcurrentBag<ErrorItem> ErrorURLs { get; } Property Value ConcurrentBag<ErrorItem> The error ur ls. WhereFound Gets or sets the where found. public ListMapping<string, string> WhereFound { get; } Property Value ListMapping<string, string> The where found."
  },
  "api/Spidey.html": {
    "href": "api/Spidey.html",
    "title": "Namespace Spidey | Spidey API Reference",
    "keywords": "Namespace Spidey Classes Crawler Crawler class ErrorItem Error item data holder. Options Basic options class ResultFile Result file Results Results from the crawl"
  },
  "api/index.html": {
    "href": "api/index.html",
    "title": "Welcome | Spidey API Reference",
    "keywords": "Welcome Welcome to the API browser."
  },
  "articles/intro.html": {
    "href": "articles/intro.html",
    "title": "Code | Spidey API Reference",
    "keywords": "Code using BigBook; using Microsoft.Extensions.DependencyInjection; namespace Spidey.Example { /// <summary> /// Example program for Spidey /// </summary> internal class Program { /// <summary> /// Defines the entry point of the application. /// </summary> /// <param name=\"args\">The arguments.</param> private static async Task Main(string[] args) { // We need to setup the service provider var Services = new ServiceCollection() // We need to first add the crawler and subsequent dependencies .AddCanisterModules() // And add our options ?.AddSingleton(new Options { // We want to allow these locations to be crawled Allow = { \"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\" }, // We want to use these credentials for authentication against the server Credentials = new System.Net.NetworkCredential(\"username\", \"password\"), // We want to ignore these locations Ignore = { \"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\" }, // When we find a new item, we want to print the filename to the console ItemFound = x => System.Console.WriteLine(x.FileName), // The maximum delay between requests MaxDelay = 1000, // The minimum delay between requests MinDelay = 100, // We want to start our crawl from these locations StartLocations = { \"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js\" }, // We want to use a proxy server at http://localhost:8888 Proxy = new System.Net.WebProxy(\"http://localhost:8888\"), // We want to use 4 workers NumberWorkers = 4, // We don't want to use the default credentials UseDefaultCredentials = false }) ?.BuildServiceProvider(); if (Services is null) return; // Let's start by creating a crawler var Crawler = Services.GetRequiredService<Crawler>(); // Now we can start the crawl var Results = await Crawler.StartCrawlAsync().ConfigureAwait(false); if (Results is null) return; // We can see the urls that were crawled Console.WriteLine(\"Found the following URLs:\"); Console.WriteLine(Results.CompletedURLs.ToString(x => x, \"\\n\")); // We can also see where the urls were found Console.WriteLine(\"The following URLs were discovered from these locations:\"); Console.WriteLine(Results.WhereFound.ToString(x => $\"{x.Key}: {x.Value.ToString(y => y)}\", \"\\n\")); // And the urls that had errors Console.WriteLine(\"And the following URLs had errors:\"); Console.WriteLine(Results.ErrorURLs.ToString(x => $\"{x.Url} ({x.StatusCode}): {x.Error}\", \"\\n\")); } } }"
  },
  "index.html": {
    "href": "index.html",
    "title": "Spidey | Spidey API Reference",
    "keywords": "Spidey Library to help with crawling web content. Compatible with .Net Core and .Net Framework. Setting up the Library Spidey relies on Canister in order to hook itself up. In order for this to work, you must do the following at startup: new ServiceCollection().AddCanisterModules(); The AddCanisterModules function is an extension method that registers it with the IoC container. When this is done, Spidey is ready to use. Basic Usage Spidey really boils down to using one class called Crawler: ServiceCollection.AddSingleton(new Options { ItemFound = FoundFile=>{} //The callback method used when a new page is discovered. Allow = new List<string> { \"http://mywebsite\", \"http://mywebsite2\" }, //Regexes of what sites/pages are allowed to be crawled. FollowOnly = new List<string> { \"...\" }, //Regexes of pages to only follow links that are found on them. Ignore = new List<string> { \"...\" }, //Regexes that the system will ignore when they are encountered. StartLocations = new List<string> { \"http://mywebsite\", \"http://mywebsite2\" }, //Starting URLs for the crawler. UrlReplacements = new Dictionary<string,string> {...} //When the system hits one of the keys in the dictionary, it will replace it with the value. }); Note that it is recommended that you actually register the Options object in your ServiceCollection and resolve the Crawler object from the service provider but it is not required. You can simply new up an instance of Crawler if you want. Anyway, the Options class has a number of properties, some of which are not displayed above such as NetworkCredentials, UseDefaultCredentials, and Proxy. The callback method is what will be called by the system once a link's info has been received and looks like this: void CallbackMethod(ResultFile obj) { ... } The library will handle parsing of links found within the page, downloading the content, etc. for the most part. At this point all you have to do is call the StartCrawl method: MyCrawler.StartCrawl(); Customization Note that it's possible to customize the crawler's various parts. The system is divided into the following sections: Content Parser (IContentParser) - This parses the resulting data and converts it to the ResultFile object. Engine (IEngine) - This downloads the content from the server. Link Discoverer (ILinkDiscoverer) - Takes the content from the engine and looks for links to other resources. Processor (IProcessor) - Takes the parsed content and hands it off to your code. The default one simply calls the method provided in the options. Scheduler (IScheduler) - Handles handing out work to the various workers. Pipeline (IPipeline) - Manages the various parts of the process by feeding the content to the next bit of the process. These subsystems all implement interfaces found in the Spidey.Engines.Interfaces namespace. In order to replace the default in any of these systems all you need to do is create a class that implements the interface that you want to replace. After that the system will automatically pick it up if resolved from the service provider. If you, instead, new up a Crawler object then you will need to compose the Pipeline object. Installation The library is available via Nuget with the package name \"Spidey\". To install it run the following command in the Package Manager Console: Install-Package Spidey FAQ Is it possible to run the crawler using multiple nodes? The default scheduler assumes that you are only running the crawler from one location and doesn't talk to other instances of the application. But it is possible to replace the scheduler with one that will talk via some mechanism like a database to coordinate work between instances and is recommended for more complex setups. Build Process In order to build the library you will require the following: Visual Studio 2019 Other than that, just clone the project and you should be able to load the solution and build without too much effort."
  }
}